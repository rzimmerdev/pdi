# Semantic Classification for Satellite Imagery
Participants: 

1) Jo√£o Pedro Duarte Nunes - 12542460

2) Rafael Zimmer - 12542612

3) Eduardo Figueiredo Freire Andrade - 11232820

4) Daniel Carvalho Dantas - 10685702

## About
This repository aims to perform pixel wise image segmentation of buildings using a dataset containing top-down satellite images of cities in Dubai.

The dataset used during training can be found [here](https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery).
All images are composed by an original satellite photo, as well as a labeled mask image, with different colors corresponding to different elements, such as:
1.  Building: #3C1098 (dark purple)
2.  Land (unpaved area): #8429F6 (magenta)
3.  Road: #6EC1E4 (cyan)
4.  Vegetation: #FEDD3A (yellow)
5.  Water: #E2A929 (orange)
6.  Unlabeled: #9B9B9B (gray)

An example pair is as follows:
Original Image:

![Example image](https://github.com/rzimmerdev/pdi-2022/blob/fd223248712c53291b250771e0a23baa9aa1b164/about/example_image.jpg)

Predicted Image:

![Example mask](https://github.com/rzimmerdev/pdi-2022/blob/fd223248712c53291b250771e0a23baa9aa1b164/about/example_mask.png)

## Image Descriptors
Firstly, we applied image description methods as to evaluate the overall correctness and quality of the original image. As all images were taken by satellites, they are expected to have at least some small kind of degradation, so studying them beforehand by using histograms and texture analysis gives some direction as to which pre-processing methods to use.

Firstly, we used LBP to generate a texture feature histogram of some images in the dataset, trying to find some feature that best described the buildings view we are trying to find.
Next, we loaded some images using the HSV channel, as to observe the saturation and hue channels and decide if the images needed some kind of contrast correction.
Finally, we generated a histogram for each color channel to verify that the images really had some kind of noise.


## Image Pre-processing
After having visualized the images in the HSV channel, we applied a contrast enhancement algorithm and tweaked the saturation channel of each image to try and achieve a better result during the segmentation training part, as most images had overall low color change in the borders in the saturation channel view.

We also applied a denoising algorithm to remove noise generated by the satellite photography.

## Image Segmentation
To read more about the segmentation algorithms used, as well as their performance and development, access the [About](https://github.com/rzimmerdev/pdi-2022/tree/main/about) page.

# Reproducing and testing
The dataset is stored under the `data` folder, and each `Tile` subfolder has a *images* and a *masks* folder, with JPG and PNG files respectively.
If you want to clone the project and run the scripts locally, access the requirements.txt file to see which packages are required to run the scripts. After installing the required packages, use the "preprocess.py" script to generate all preprocessed images (open the script to learn more about which images can be used and where to find them). To segment the images yourself, use the "segmentation.py" script to segment the images using the more basic methods, such as the Otsu filter or the Watershed algorithm. If you wish to run the UNet model, and eventually obtain a better segmentation score, run the "model_predict.py" script. It is important to note that both scripts will output the predicted images into the predictions directory.

# Conclusions and Considerations
The "Otsu Thresholding" method seems to fit well for the means of this project. The streets in the images are still too evident, though. In comparison, the Watershed gradient matrix was not able to perform as well, even though it didn't segment bigger areas such as lakes or roads as false positives, while the Otsu filter sometimes missclassified much bigger regions. After trying to apply both color-wise and region-wise segmentation, we decided to use a Convolutional Neural Network to try and obtain a smaller error value (the UNet was choosed for this task, as we don't have a big dataset to use). In the end, the UNet wastly outperformed all the previously tried methods, and was choosen for this specific assignment at the end.
