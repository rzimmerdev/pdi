{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.nn import functional\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class DoubleConvolutionLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolve = nn.Sequential(\n",
    "            nn.Conv2d(in_features, out_features, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_features, out_features, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.convolve(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.maxpool_convolve = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConvolutionLayer(in_features, out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.maxpool_convolve(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.ConvTranspose2d(in_features, in_features // 2, kernel_size=2, stride=2)\n",
    "        self.convolve = DoubleConvolutionLayer(in_features, out_features)\n",
    "\n",
    "    @staticmethod\n",
    "    def crop(encoder_features, x):\n",
    "        height, weight = x.shape[2], x.shape[3]\n",
    "\n",
    "        # Returning new cropped matrix for input encoder features\n",
    "        return torchvision.transforms.CenterCrop([height, weight])(encoder_features)\n",
    "\n",
    "    def forward(self, x, x_pass):\n",
    "\n",
    "        x_scaled = self.up(x)\n",
    "        offset_y = x_pass.size()[2] - x_scaled.size()[2]\n",
    "        offset_x = x_pass.size()[3] - x_scaled.size()[3]\n",
    "\n",
    "        x_padded = functional.pad(x_scaled, [offset_x // 2, offset_x // 2 + offset_x % 2,\n",
    "                                             offset_y // 2, offset_y // 2 + offset_y % 2])\n",
    "        x = torch.cat([x_pass, x_padded], dim=1)\n",
    "        return self.convolve(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class OutLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(OutLayer, self).__init__()\n",
    "\n",
    "        self.convolve = nn.Conv2d(in_features, out_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convolve(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        encode_channels = (64, 128, 256, 512, 1024)\n",
    "        decode_channels = (1024, 512, 256, 256, 128, 64)\n",
    "\n",
    "        self.input_layer = DoubleConvolutionLayer(n_channels, encode_channels[0])\n",
    "\n",
    "        self.decoders = [Encoder(encode_channels[i], encode_channels[i + 1]) for i in range(len(encode_channels - 1))]\n",
    "        self.encoders = [Decoder(decode_channels[i], decode_channels[i + 1]) for i in range(len(decode_channels - 1))]\n",
    "\n",
    "        self.output_layer = OutLayer(decode_channels[-1], n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        skip_layers = []\n",
    "\n",
    "        for encoder in self.encoders:\n",
    "            skip_layers.append(x)\n",
    "            x = encoder(x)\n",
    "\n",
    "        for idx, decoder in enumerate(self.decoders):\n",
    "            x = decoder(x, skip_layers[len(skip_layers) - idx - 1])\n",
    "\n",
    "        classes = self.output_layer(x)\n",
    "        return classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}