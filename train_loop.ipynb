{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset_and_Dataloader.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKlwi7XDpKsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4b3379-c435-4fc4-a91b-267d2e6214be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DvrMCxzJrqKKN-rU-klk7_XikfhaCr3j\n",
            "To: /content/pdi-2022-main.zip\n",
            "100% 52.6M/52.6M [00:00<00:00, 79.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1DvrMCxzJrqKKN-rU-klk7_XikfhaCr3j'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"pdi-2022-main.zip\" -d \"./\""
      ],
      "metadata": {
        "id": "ZZbfYST3tthg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "import os"
      ],
      "metadata": {
        "id": "_Wr0VYq430pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROCESSED_IMAGES_PATH = 'pdi-2022-main/data/processed'\n",
        "ORIGINAL_IMAGES_PATH = 'pdi-2022-main/data/original'"
      ],
      "metadata": {
        "id": "LwdBe3me2e71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criação do Dataset"
      ],
      "metadata": {
        "id": "rZ71MkJW3Ebp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_path(path):\n",
        "    paths = []\n",
        "    if(os.path.isdir(path)):\n",
        "        for child in os.listdir(path):\n",
        "             paths += get_image_path(path + os.path.sep + child)\n",
        "    else:\n",
        "         print(path.split())\n",
        "         return [path]\n",
        "   \n",
        "    return paths"
      ],
      "metadata": {
        "id": "BlOReYVVFf-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_masks_path(path):\n",
        "    paths = []\n",
        "    if(os.path.isdir(path)):\n",
        "        for child in os.listdir(path):\n",
        "            if child != 'images':\n",
        "                paths += get_masks_path(path + os.path.sep + child)\n",
        "    else:\n",
        "         return [path]\n",
        "   \n",
        "    return paths"
      ],
      "metadata": {
        "id": "wlvrYP_DIGWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(get_image_path(PROCESSED_IMAGES_PATH))"
      ],
      "metadata": {
        "id": "d6tZ3KchG2Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import read_image\n",
        "\n",
        "class ProcessedImagesDataset(Dataset):\n",
        "    def __init__(self, processed_img_dir, original_img_dir):\n",
        "        self.processed_img_dir = processed_img_dir\n",
        "        self.img_paths = sorted(get_image_path(self.processed_img_dir))\n",
        "        self.masks_path = sorted(get_masks_path(original_img_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = read_image(img_path)\n",
        "        mask_path = self.img_masks_path[idx]\n",
        "        mask = read_image(mask_path)\n",
        "        \n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "GX1Up7C23v9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ProcessedImagesDataset(PROCESSED_IMAGES_PATH, ORIGINAL_IMAGES_PATH)"
      ],
      "metadata": {
        "id": "FPFLoOUCLIDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaCAyKs1Lcms",
        "outputId": "c7bcc030-831c-4b63-8b23-e0210de3fa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criação do Dataloader"
      ],
      "metadata": {
        "id": "_ivkYniF3Hem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "train_data, test_data = random_split(dataset, [50, 22])\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=6, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=6, shuffle=True)"
      ],
      "metadata": {
        "id": "xKOytaIbJ7UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino"
      ],
      "metadata": {
        "id": "d9ng1GaUQHQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bed9-XL_-CXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model, device):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device).unsqueeze(1) # Label doesn't have a channel\n",
        "\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            dice_score += (2 * (preds * y).sum())/((preds + y).sum() + 1e-8)\n",
        "\n",
        "    print(f\"Dice score: {dice_score/ len(loader)}\")\n",
        "    print(f\"Got {num_correct}/{num_pixels} with accuracy {num_correct*100/num_pixels:.2f}\")"
      ],
      "metadata": {
        "id": "K9sa5cv5oG1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler, epochs, device):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data, targets) in enumerate(loader):\n",
        "            data = data.to(device)\n",
        "            targets = targets.float().unsqueeze(1).to(device)\n",
        "\n",
        "            # forward\n",
        "            with torch.cuda.amp.autocast():\n",
        "                predictions = model(data)\n",
        "                loss = loss_fn(predictions, targets)\n",
        "\n",
        "            # backward\n",
        "            optim.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "\n",
        "        print (f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "FdOr8SITQJfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste"
      ],
      "metadata": {
        "id": "DIqJXW1v8XwL"
      }
    }
  ]
}